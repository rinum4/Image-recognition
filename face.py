"""
Прикладная задача: конвейер распознавания лиц 
"""
# мы рассмотрим одну из подобных методик выделения признаков на картинках, 
# гистограмму направленных градиентов (histogram of oriented gradients, HOG,
# см. https://ru.wikipedia.org/wiki/Гистограмма_направленных_градиентов), 

#%matplotlib inline       
import matplotlib.pyplot as plt       
import seaborn as sns; sns.set()       
import numpy as np

# Гистограмма направленных градиентов — простая процедура выделения признаков,
# разработанная для идентификации пешеходов на изображениях. Метод HOG включает
# следующие этапы. 
# 1. Необязательная предварительная нормализация изображений. В результате получаются
#    признаки, слабо зависящие от изменений освещенности. 
# 2. Операция свертывания изображения с помощью двух фильтров, чувствительных к
#    горизонтальным и вертикальным градиентам яркости. Это позволяет уловить
#    информацию о границах, контурах и текстурах изображения. 
# 3. Разбивка изображения на ячейки заранее определенного размера и вычисление
#    гистограммы направлений градиентов в каждой из ячеек.
# 4. Нормализация гистограмм в каждой из ячеек путем сравнения с несколькими
#    близлежащими ячейками. Это еще больше подавляет влияние освещенности на
#    изображение. 
# 5. Формирование одномерного вектора признаков из информации по каждой ячейке. 

# В проект Scikit-Image1 встроена процедура выделения признаков на основе HOG,
# которую мы сможем достаточно быстро применить на практике и визуализировать
# направленные градиенты во всех ячейках 
from skimage import data, color, feature       
import skimage.data

image = color.rgb2gray(data.chelsea())       
hog_vec, hog_vis = feature.hog(image, visualise=True)
fig, ax = plt.subplots(1, 2, figsize=(12, 6),
                       subplot_kw=dict(xticks=[], yticks=[]))       
ax[0].imshow(image, cmap='gray')       
ax[0].set_title('input image')
ax[1].imshow(hog_vis)       
ax[1].set_title('visualization of HOG features');

# =============================================================================
# Метод HOG в действии: простой детектор лиц
# =============================================================================
# На основе этих признаков HOG можно создать простой алгоритм обнаружения лиц с
# помощью любого из оценивателей библиотеки Scikit-Learn. Мы воспользуемся линейным
# методом опорных векторов 
# Алгоритм включает следующие шаги. 
# 1. Получение миниатюр изображений, на которых представлены лица, для формирования
#    набора «положительных» обучающих выборок. 
# 2. Получение миниатюр изображений, на которых не представлены лица для формирования
#    набора «отрицательных» обучающих выборок. 
# 3. Выделение HOG-признаков из этих обучающих выборок. 
# 4. Обучение линейного SVM-классификатора на этих выборках. 
# 5. В случае «незнакомого» изображения перемещаем по изображению скользящее окно,
#    применяя нашу модель для определения того, содержится ли в этом окне лицо или
#    нет. 
# 6. Если обнаруженные лица частично пересекаются, объединяем их в одно окно

# 1. Найдем положительные обучающие выборки с разнообразными лицами
from sklearn.datasets import fetch_lfw_people       
faces = fetch_lfw_people()       
positive_patches = faces.images
positive_patches.shape

# 2. Далее нам необходимо найти набор миниатюр такого же размера, на которых не
# изображены лица. Чтобы сделать это, можно, например, взять любой корпус исходных
# изображений и извлечь из них миниатюры в различных масштабах. Воспользуемся
# некоторыми из поставляемых вместе с пакетом Scikit-Image изображений, а также
# классом PatchExtractor библиотеки Scikit-Lear
from skimage import data, transform

imgs_to_use = ['camera', 'text', 'coins', 'moon',
               'page', 'clock', 'immunohistochemistry',
               'chelsea', 'coffee', 'hubble_deep_field']       
images = [color.rgb2gray(getattr(data, name)())                 
          for name in imgs_to_use]

from sklearn.feature_extraction.image import PatchExtractor
# извлекаем из них миниатюры в различных масштабах
def extract_patches(img, N, scale=1.0,                    
                    patch_size=positive_patches[0].shape):    
    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))    
    extractor = PatchExtractor(patch_size=extracted_patch_size,
                               max_patches=N, random_state=0)    
    patches = extractor.transform(img[np.newaxis])    
    if scale != 1:        
        patches = np.array([transform.resize(patch, patch_size)
                            for patch in patches])    
    return patches

negative_patches = np.vstack([extract_patches(im, 1000, scale)
                             for im in images for scale in [0.5, 1.0, 2.0]]) 
negative_patches.shape

# У нас теперь есть 30 000 подходящих фрагментов изображений, не содержащих лиц.
# Рассмотрим некоторые из них, чтобы лучше представить, как они выглядят 
fig, ax = plt.subplots(6, 10)       
for i, axi in enumerate(ax.flat):           
    axi.imshow(negative_patches[500 * i], cmap='gray')           
    axi.axis('off')

# 3. При наличии положительных и отрицательных выборок мы можем их объединить и
#    вычислить HOG-признаки.
from itertools import chain       
X_train = np.array([feature.hog(im)                           
                    for im in chain(positive_patches,
                                           negative_patches)])       
y_train = np.zeros(X_train.shape[0])       
y_train[:positive_patches.shape[0]] = 1

# Итак, мы получили 43 000 обучающих выборок в 1215-мерном пространстве и наши
# данные находятся в подходящем для библиотеки Scikit-Learn виде

# вначале воспользуемся простым Гауссовым наивным байесовским классификатором,
# чтобы было с чем сравнивать
from sklearn.naive_bayes import GaussianNB       
from sklearn.model_selection import cross_val_score       
cross_val_score(GaussianNB(), X_train, y_train)
# даже наивный байесовский алгоритм достигает более чем 90%-ной точности

# Попробуем теперь метод опорных векторов с поиском по сетке из нескольких
# вариантов параметра 
from sklearn.svm import LinearSVC        
from sklearn.model_selection import GridSearchCV        
grid = GridSearchCV(LinearSVC(), {'C': [1.0, 2.0, 4.0, 8.0]})        
grid.fit(X_train, y_train)        
grid.best_score_
grid.best_params_

# Обучаем на полной выборке
model = grid.best_estimator_        
model.fit(X_train, y_train)

# Теперь, когда у нас есть модель, возьмем новое изображение и посмотрим, насколько
# хорошо она в нем себя покажет
test_image = skimage.data.astronaut()        
test_image = skimage.color.rgb2gray(test_image)        
test_image = skimage.transform.rescale(test_image, 0.5)        
test_image = test_image[:160, 40:180]
plt.imshow(test_image, cmap='gray')        
plt.axis('off');

# Далее создадим окно, которое будет перемещаться по фрагментам этого изображения
# с вычислением HOG-признаков для каждого фрагмента
def sliding_window(img, patch_size=positive_patches[0].shape,
                           istep=2, jstep=2, scale=1.0):            
    Ni, Nj = (int(scale * s) for s in patch_size)            
    for i in range(0, img.shape[0] - Ni, istep):                
        for j in range(0, img.shape[1] - Ni, jstep):                    
            patch = img[i:i + Ni, j:j + Nj]                    
            if scale != 1:                        
                patch = transform.resize(patch, patch_size)                    
            yield (i, j), patch
 
indices, patches = zip(*sliding_window(test_image))        
patches_hog = np.array([feature.hog(patch) for patch in patches])        
patches_hog.shape
# возьмем эти фрагменты, для которых вычислены признаки HOG, и воспользуемся нашей
# моделью, чтобы определить, содержат ли какие-то из них лица
labels = model.predict(patches_hog)        
labels.sum()
# среди 2000 фрагментов найдено 33 лица

# Воспользуемся имеющейся о фрагментах информацией, чтобы определить, где в нашем
# контрольном изображении они располагаются, нарисовав их границы в виде
# прямоугольников 
fig, ax = plt.subplots()        
ax.imshow(test_image, cmap='gray')
ax.axis('off')

Ni, Nj = positive_patches[0].shape        
indices = np.array(indices)
for i, j in indices[labels == 1]:            
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                                       alpha=0.3, lw=2,
                                       facecolor='none'))

# =============================================================================
# Предостережения и дальнейшие усовершенствования
# =============================================================================
# в него не помешает внести несколько усовершенствований.  
# > Наша обучающая последовательность, особенно в части отрицательных признаков, неполна.
# Основная проблема заключается в том, что существует множество напоминающих лица текстур, не
# включенных в нашу обучающую последовательность, поэтому нынешняя модель будет склонна
# выдавать ложноположительные результаты. Это будет заметно, если попытаться выполнить
# предыдущий алгоритм для полного изображения астронавта: текущая модель приведет
# к множеству ложных обнаружений лиц в других областях изображения.
# Можно было бы попытаться решить эту проблему путем добавления в отрицательную обучающую
# последовательность множества разнообразных изображений, и это, вероятно, действительно
# привело бы к некоторому улучшению ситуации. Другой способ — использование
# узконаправленного подхода, например, hard negative mining. При подходе hard negative
# mining, берется новый, еще не виденный классификатором набор изображений и все фрагменты
# в нем, соответствующие ложноположительным результатам, явным образом добавляются в
# качестве отрицательных примеров в обучающую последовательность до повторного обучения
# классификатора
# > Текущий конвейер выполняет поиск только при одном значении масштаба. В текущем виде
# наш алгоритм будет распознавать только те лица, чей размер примерно равен 62 × 47
# пикселов. Эту проблему можно решить довольно просто путем применения скользящих окон
# различных размеров и изменения размера каждого из фрагментов с помощью функции
# skimage.transform.resize до подачи его на вход модели. На самом деле используемая
# здесь вспомогательная функция sliding_window() уже учитывает этот нюанс
# > Желательно комбинировать перекрывающиеся фрагменты, на которых обнаружены лица.
# В случае готового к промышленной эксплуатации конвейера получение 30 обнаружений
# одного и того же лица представляется нежелательным. Хотелось бы сократить
# перекрывающиеся группы обнаруженных лиц до одного. Это можно сделать с помощью
# одного из методов кластеризации без учителя (хороший кандидат на эту роль —
# кластеризация путем сдвига среднего значения (meanshift clustering)) или посредством
# процедурного подхода, например алгоритма подавления немаксимумов (nonmaximum suppression), часто используемого в сфере машинного зрения. 
# > Конвейер должен быть более продвинутым. После решение вышеописанных проблем неплохо
# было бы создать более продвинутый конвейер, который бы получал на входе обучающие
# изображения и выдавал предсказания на основе скользящих окон. Именно в этом вопросе
# язык Python как инструмент науки о данных демонстрирует все свои возможности: приложив
# немного труда, мы сможем скомпоновать наш предварительный код с качественно
# спроектированным объектно-ориентированным API, обеспечивающим для пользователя легкость
# в использовании. 
# Желательно обдумать возможность применения более современных средств предварительной
# обработки, таких как глубокое обучение. Наконец, мне хотелось бы добавить, что HOG
# и другие процедурные методы выделения признаков для изображений более не считаются
# современными. Вместо них многие современные конвейеры обнаружения объектов используют
# различные варианты глубоких нейронных сетей. Нейронные сети можно рассматривать как
# оцениватель, определяющий оптимальную стратегию выделения признаков на основе самих
# данных, а не полагающийся на интуицию пользователя. Знакомство с методами глубоких
# нейронных сетей выходит за рамки этого раздела концептуально (и вычислительно!), хотя
# некоторые инструменты с открытым исходным кодом, такие как TensorFlow
# (https://www.tensorflow.org/), выпущенный корпорацией Google, сделали в последнее
# время подход глубокого обучения значительно более доступным